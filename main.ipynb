{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import axelrod as axl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import mmread\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"fb_graph/matname.mtx\"\n",
    "sparse_matrix = mmread(file_path)\n",
    "graph = nx.Graph(sparse_matrix)\n",
    "\n",
    "strategies = [\n",
    "    axl.Cooperator(),\n",
    "    axl.Defector(),\n",
    "    axl.TitForTat(),\n",
    "    axl.Grudger(),\n",
    "    axl.Random(),\n",
    "    axl.ZDExtortion(),\n",
    "    axl.Capri(),\n",
    "    axl.Appeaser()\n",
    "]\n",
    "\n",
    "players = []\n",
    "for node in graph.nodes:\n",
    "    players.append(np.random.choice(strategies))\n",
    "\n",
    "# turns is ther number of iterations between each pair\n",
    "spatial_tournament = axl.Tournament(\n",
    "    players, edges=graph.edges, turns=100, repetitions=1)\n",
    "results = spatial_tournament.play(filename=\"test.csv\")\n",
    "\n",
    "df = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Interaction index', 'Player index', 'Opponent index', 'Repetition',\n",
      "       'Player name', 'Opponent name', 'Actions', 'Score', 'Score difference',\n",
      "       'Turns', 'Score per turn', 'Score difference per turn', 'Win',\n",
      "       'Initial cooperation', 'Cooperation count', 'CC count', 'CD count',\n",
      "       'DC count', 'DD count', 'CC to C count', 'CC to D count',\n",
      "       'CD to C count', 'CD to D count', 'DC to C count', 'DC to D count',\n",
      "       'DD to C count', 'DD to D count', 'Good partner'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"100_turns.csv\")\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting best strageties for X turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Strategies:\n",
      "Strategy: Appeaser - Mean Score: 15469.33\n",
      "Strategy: CAPRI - Mean Score: 16736.94\n",
      "Strategy: Cooperator - Mean Score: 15437.00\n",
      "Strategy: Grudger - Mean Score: 18450.86\n",
      "Strategy: Tit For Tat - Mean Score: 16543.53\n",
      "\n",
      "Bad Strategies:\n",
      "Strategy: Defector - Mean Score: 14075.96\n",
      "Strategy: Random: 0.5 - Mean Score: 11875.78\n",
      "Strategy: ZD-Extortion: 0.2, 0.1, 1 - Mean Score: 12092.30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load results from the tournament\n",
    "df = pd.read_csv(\"100_turns.csv\")\n",
    "\n",
    "# Compute total score for each player\n",
    "scores = df.groupby(\"Player index\")[\"Score\"].sum()\n",
    "\n",
    "# Extract unique strategies based on the \"Player index\" and \"Player name\"\n",
    "strategy_mapping = df[[\"Player index\", \"Player name\"]\n",
    "                      ].drop_duplicates().set_index(\"Player index\")[\"Player name\"]\n",
    "\n",
    "# Add strategy information to the scores DataFrame\n",
    "scores_with_strategy = pd.DataFrame(scores).reset_index()\n",
    "scores_with_strategy[\"Strategy\"] = scores_with_strategy[\"Player index\"].map(\n",
    "    strategy_mapping)\n",
    "\n",
    "# Compute mean score by strategy\n",
    "strategy_scores = scores_with_strategy.groupby(\"Strategy\")[\"Score\"].mean()\n",
    "\n",
    "# Calculate the overall mean score\n",
    "overall_mean_score = strategy_scores.mean()\n",
    "\n",
    "# Categorize strategies as good or bad based on their mean score\n",
    "good_strategies = strategy_scores[strategy_scores > overall_mean_score]\n",
    "bad_strategies = strategy_scores[strategy_scores <= overall_mean_score]\n",
    "\n",
    "# Output the results\n",
    "print(\"Good Strategies:\")\n",
    "for strategy, mean_score in good_strategies.items():\n",
    "    print(f\"Strategy: {strategy} - Mean Score: {mean_score:.2f}\")\n",
    "\n",
    "print(\"\\nBad Strategies:\")\n",
    "for strategy, mean_score in bad_strategies.items():\n",
    "    print(f\"Strategy: {strategy} - Mean Score: {mean_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks what is better, playing as Defector or Cooperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Cooperators: 222.88 (Std Dev: 107.67)\n",
      "Average Score for Defectors: 202.53 (Std Dev: 141.99)\n",
      "It is better to play as a Cooperator.\n",
      "\n",
      "Performance of Cooperators Against Opponents:\n",
      "                                 mean        std\n",
      "Opponent name                                   \n",
      "Appeaser                   300.000000   0.000000\n",
      "CAPRI                      300.000000   0.000000\n",
      "Cooperator                 300.000000   0.000000\n",
      "Defector                     0.000000   0.000000\n",
      "Grudger                    300.000000   0.000000\n",
      "Random: 0.5                150.228571  15.106975\n",
      "Tit For Tat                300.000000   0.000000\n",
      "ZD-Extortion: 0.2, 0.1, 1  134.112330  21.726942\n",
      "\n",
      "Performance of Defectors Against Opponents:\n",
      "                                 mean        std\n",
      "Opponent name                                   \n",
      "Appeaser                   300.000000   0.000000\n",
      "CAPRI                      104.000000   0.000000\n",
      "Cooperator                 500.000000   0.000000\n",
      "Defector                   100.000000   0.000000\n",
      "Grudger                    104.000000   0.000000\n",
      "Random: 0.5                300.112276  19.917516\n",
      "Tit For Tat                104.000000   0.000000\n",
      "ZD-Extortion: 0.2, 0.1, 1  104.886170   2.083319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load results from the tournament\n",
    "df = pd.read_csv(\"100_turns.csv\")\n",
    "\n",
    "# Separate games based on the player's strategy\n",
    "cooperator_games = df[df[\"Player name\"] == \"Cooperator\"]\n",
    "defector_games = df[df[\"Player name\"] == \"Defector\"]\n",
    "\n",
    "# Calculate mean and standard deviation for Cooperators\n",
    "cooperator_avg_score = cooperator_games[\"Score\"].mean()\n",
    "cooperator_std_dev = cooperator_games[\"Score\"].std()\n",
    "\n",
    "# Calculate mean and standard deviation for Defectors\n",
    "defector_avg_score = defector_games[\"Score\"].mean()\n",
    "defector_std_dev = defector_games[\"Score\"].std()\n",
    "\n",
    "# Analyze performance based on opponent's strategy\n",
    "cooperator_vs_opponents = cooperator_games.groupby(\n",
    "    \"Opponent name\")[\"Score\"].agg([\"mean\", \"std\"])\n",
    "defector_vs_opponents = defector_games.groupby(\n",
    "    \"Opponent name\")[\"Score\"].agg([\"mean\", \"std\"])\n",
    "\n",
    "# Output the results\n",
    "print(f\"Average Score for Cooperators: {\n",
    "      cooperator_avg_score:.2f} (Std Dev: {cooperator_std_dev:.2f})\")\n",
    "print(f\"Average Score for Defectors: {\n",
    "      defector_avg_score:.2f} (Std Dev: {defector_std_dev:.2f})\")\n",
    "\n",
    "if cooperator_avg_score > defector_avg_score:\n",
    "    print(\"It is better to play as a Cooperator.\")\n",
    "elif defector_avg_score > cooperator_avg_score:\n",
    "    print(\"It is better to play as a Defector.\")\n",
    "else:\n",
    "    print(\"Playing as a Cooperator or Defector is equally effective.\")\n",
    "\n",
    "print(\"\\nPerformance of Cooperators Against Opponents:\")\n",
    "print(cooperator_vs_opponents)\n",
    "\n",
    "print(\"\\nPerformance of Defectors Against Opponents:\")\n",
    "print(defector_vs_opponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Average Score:\n",
      "Strategy: Grudger - Mean Score: 18450.86\n",
      "\n",
      "Lowest Average Score:\n",
      "Strategy: Random: 0.5 - Mean Score: 11875.78\n",
      "\n",
      "Highest Average Score Among High Cluster-Coefficient Nodes:\n",
      "Strategy: Grudger - Mean Score: 13814.28\n",
      "\n",
      "Lowest Average Score Among High Cluster-Coefficient Nodes:\n",
      "Strategy: Random: 0.5 - Mean Score: 8712.89\n",
      "\n",
      "Highest Average Score Among Low Cluster-Coefficient Nodes:\n",
      "Strategy: Grudger - Mean Score: 23181.11\n",
      "\n",
      "Lowest Average Score Among Low Cluster-Coefficient Nodes:\n",
      "Strategy: Random: 0.5 - Mean Score: 14890.87\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.io import mmread\n",
    "\n",
    "# Load results from the tournament\n",
    "df = pd.read_csv(\"100_turns.csv\")\n",
    "\n",
    "# Load the graph to compute clustering coefficients\n",
    "file_path = \"fb_graph/matname.mtx\"  # Path to your graph file\n",
    "sparse_matrix = mmread(file_path)\n",
    "graph = nx.Graph(sparse_matrix)\n",
    "\n",
    "# Compute clustering coefficients for all nodes\n",
    "clustering_coeffs = nx.clustering(graph)\n",
    "clustering_df = pd.DataFrame(list(clustering_coeffs.items()), columns=[\n",
    "                             \"Player index\", \"Clustering Coefficient\"])\n",
    "\n",
    "# Merge clustering coefficients with player scores\n",
    "scores = df.groupby(\"Player index\")[\"Score\"].sum()\n",
    "strategy_mapping = df[[\"Player index\", \"Player name\"]\n",
    "                      ].drop_duplicates().set_index(\"Player index\")[\"Player name\"]\n",
    "scores_with_clustering = pd.DataFrame(scores).reset_index()\n",
    "scores_with_clustering[\"Strategy\"] = scores_with_clustering[\"Player index\"].map(\n",
    "    strategy_mapping)\n",
    "scores_with_clustering = scores_with_clustering.merge(\n",
    "    clustering_df, on=\"Player index\")\n",
    "\n",
    "# Calculate average score for each strategy\n",
    "strategy_stats = scores_with_clustering.groupby(\n",
    "    \"Strategy\")[\"Score\"].agg([\"mean\"]).reset_index()\n",
    "\n",
    "# Find strategies with highest/lowest average scores\n",
    "highest_mean_strategy = strategy_stats.loc[strategy_stats[\"mean\"].idxmax()]\n",
    "lowest_mean_strategy = strategy_stats.loc[strategy_stats[\"mean\"].idxmin()]\n",
    "\n",
    "# Categorize nodes into high and low clustering coefficient groups\n",
    "median_clustering = scores_with_clustering[\"Clustering Coefficient\"].median()\n",
    "high_cluster_nodes = scores_with_clustering[scores_with_clustering[\"Clustering Coefficient\"] > median_clustering]\n",
    "low_cluster_nodes = scores_with_clustering[scores_with_clustering[\"Clustering Coefficient\"]\n",
    "                                           <= median_clustering]\n",
    "\n",
    "# Calculate average score for strategies among high-cluster-coefficient nodes\n",
    "high_cluster_stats = high_cluster_nodes.groupby(\n",
    "    \"Strategy\")[\"Score\"].agg([\"mean\"]).reset_index()\n",
    "highest_mean_high_cluster = high_cluster_stats.loc[high_cluster_stats[\"mean\"].idxmax(\n",
    ")]\n",
    "lowest_mean_high_cluster = high_cluster_stats.loc[high_cluster_stats[\"mean\"].idxmin(\n",
    ")]\n",
    "\n",
    "# Calculate average score for strategies among low-cluster-coefficient nodes\n",
    "low_cluster_stats = low_cluster_nodes.groupby(\n",
    "    \"Strategy\")[\"Score\"].agg([\"mean\"]).reset_index()\n",
    "highest_mean_low_cluster = low_cluster_stats.loc[low_cluster_stats[\"mean\"].idxmax(\n",
    ")]\n",
    "lowest_mean_low_cluster = low_cluster_stats.loc[low_cluster_stats[\"mean\"].idxmin(\n",
    ")]\n",
    "\n",
    "# Output results\n",
    "print(\"Highest Average Score:\")\n",
    "print(f\"Strategy: {highest_mean_strategy['Strategy']\n",
    "                   } - Mean Score: {highest_mean_strategy['mean']:.2f}\")\n",
    "\n",
    "print(\"\\nLowest Average Score:\")\n",
    "print(f\"Strategy: {lowest_mean_strategy['Strategy']\n",
    "                   } - Mean Score: {lowest_mean_strategy['mean']:.2f}\")\n",
    "\n",
    "print(\"\\nHighest Average Score Among High Cluster-Coefficient Nodes:\")\n",
    "print(f\"Strategy: {highest_mean_high_cluster['Strategy']\n",
    "                   } - Mean Score: {highest_mean_high_cluster['mean']:.2f}\")\n",
    "\n",
    "print(\"\\nLowest Average Score Among High Cluster-Coefficient Nodes:\")\n",
    "print(f\"Strategy: {lowest_mean_high_cluster['Strategy']\n",
    "                   } - Mean Score: {lowest_mean_high_cluster['mean']:.2f}\")\n",
    "\n",
    "print(\"\\nHighest Average Score Among Low Cluster-Coefficient Nodes:\")\n",
    "print(f\"Strategy: {highest_mean_low_cluster['Strategy']\n",
    "                   } - Mean Score: {highest_mean_low_cluster['mean']:.2f}\")\n",
    "\n",
    "print(\"\\nLowest Average Score Among Low Cluster-Coefficient Nodes:\")\n",
    "print(f\"Strategy: {lowest_mean_low_cluster['Strategy']\n",
    "                   } - Mean Score: {lowest_mean_low_cluster['mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating sd for every strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Stats with Normalized Standard Deviation:\n",
      "                    Strategy          mean           std  Normalized Std\n",
      "0                   Appeaser  15469.325130  14070.697624        0.633101\n",
      "1                      CAPRI  16736.940431  14648.673434        0.729308\n",
      "2                 Cooperator  15437.002472  14131.982741        0.643303\n",
      "3                   Defector  14075.962914  12672.643093        0.400390\n",
      "4                    Grudger  18450.861250  16084.529397        0.968311\n",
      "5                Random: 0.5  11875.777512  10267.230558        0.000000\n",
      "6                Tit For Tat  16543.525292  16274.905026        1.000000\n",
      "7  ZD-Extortion: 0.2, 0.1, 1  12092.302108  11657.093771        0.231348\n",
      "\n",
      "Good Strategies:\n",
      "Strategy: Appeaser - Mean Score: 15469.33 - Normalized Std: 0.63\n",
      "Strategy: CAPRI - Mean Score: 16736.94 - Normalized Std: 0.73\n",
      "Strategy: Cooperator - Mean Score: 15437.00 - Normalized Std: 0.64\n",
      "Strategy: Grudger - Mean Score: 18450.86 - Normalized Std: 0.97\n",
      "Strategy: Tit For Tat - Mean Score: 16543.53 - Normalized Std: 1.00\n",
      "\n",
      "Bad Strategies:\n",
      "Strategy: Defector - Mean Score: 14075.96 - Normalized Std: 0.40\n",
      "Strategy: Random: 0.5 - Mean Score: 11875.78 - Normalized Std: 0.00\n",
      "Strategy: ZD-Extortion: 0.2, 0.1, 1 - Mean Score: 12092.30 - Normalized Std: 0.23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load results from the tournament\n",
    "df = pd.read_csv(\"100_turns.csv\")\n",
    "\n",
    "# Compute total score for each player\n",
    "scores = df.groupby(\"Player index\")[\"Score\"].sum()\n",
    "\n",
    "# Extract unique strategies based on the \"Player index\" and \"Player name\"\n",
    "strategy_mapping = df[[\"Player index\", \"Player name\"]\n",
    "                      ].drop_duplicates().set_index(\"Player index\")[\"Player name\"]\n",
    "\n",
    "# Add strategy information to the scores DataFrame\n",
    "scores_with_strategy = pd.DataFrame(scores).reset_index()\n",
    "scores_with_strategy[\"Strategy\"] = scores_with_strategy[\"Player index\"].map(\n",
    "    strategy_mapping)\n",
    "\n",
    "# Compute mean and standard deviation scores by strategy\n",
    "strategy_stats = scores_with_strategy.groupby(\n",
    "    \"Strategy\")[\"Score\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "\n",
    "# Normalize the standard deviation\n",
    "std_min = strategy_stats[\"std\"].min()\n",
    "std_max = strategy_stats[\"std\"].max()\n",
    "epsilon = 1e-8  # Small constant to avoid division by zero\n",
    "\n",
    "strategy_stats[\"Normalized Std\"] = (\n",
    "    strategy_stats[\"std\"] - std_min) / (std_max - std_min + epsilon)\n",
    "\n",
    "# Output the results\n",
    "print(\"Strategy Stats with Normalized Standard Deviation:\")\n",
    "print(strategy_stats)\n",
    "\n",
    "# Separate good and bad strategies based on normalized mean score\n",
    "overall_mean_score = strategy_stats[\"mean\"].mean()\n",
    "good_strategies = strategy_stats[strategy_stats[\"mean\"] > overall_mean_score]\n",
    "bad_strategies = strategy_stats[strategy_stats[\"mean\"] <= overall_mean_score]\n",
    "\n",
    "print(\"\\nGood Strategies:\")\n",
    "for _, row in good_strategies.iterrows():\n",
    "    print(f\"Strategy: {row['Strategy']} - Mean Score: {row['mean']          :.2f} - Normalized Std: {row['Normalized Std']:.2f}\")\n",
    "\n",
    "print(\"\\nBad Strategies:\")\n",
    "for _, row in bad_strategies.iterrows():\n",
    "    print(f\"Strategy: {row['Strategy']} - Mean Score: {row['mean']          :.2f} - Normalized Std: {row['Normalized Std']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ranking of nodes and relations cutting and relations making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading graph..\n",
      "finished reading graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:28<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to csv file...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import csv\n",
    "\n",
    "from scipy.io import mmread\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Define all strategies (including new ones)\n",
    "STRATEGIES = [\n",
    "    \"TitForTat\",\n",
    "    \"AlwaysDefect\",\n",
    "    \"AlwaysCooperate\",\n",
    "    \"Grudger\",\n",
    "    \"Pavlovian\",\n",
    "    \"Appeaser\",\n",
    "    \"Capri\"\n",
    "]\n",
    "\n",
    "# Payoff matrix and helper functions\n",
    "PAYOFF_MATRIX = {\n",
    "    (\"C\", \"C\"): (3, 3),\n",
    "    (\"C\", \"D\"): (0, 5),\n",
    "    (\"D\", \"C\"): (5, 0),\n",
    "    (\"D\", \"D\"): (1, 1),\n",
    "}\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.strategy = random.choice(STRATEGIES)  # Random initial strategy\n",
    "        self.strategy_history = []  # Track strategy at the start of each iteration\n",
    "        self.average_payoff_history = []  # Average payoff at the end of each iteration\n",
    "        # {opponent_name: [(my_action, opp_action)]}\n",
    "        self.memory = defaultdict(list)\n",
    "        self.score = 0\n",
    "        self.reputation = 1.0\n",
    "        self.defection_count = defaultdict(int)\n",
    "        self.interaction_count = 0  # Track total interactions\n",
    "\n",
    "    def decide(self, opponent):\n",
    "        # First interaction: use opponent's reputation\n",
    "        if opponent.name not in self.memory:\n",
    "            return \"C\" if random.random() < opponent.reputation else \"D\"\n",
    "\n",
    "        # Strategy-specific logic\n",
    "        if self.strategy == \"TitForTat\":\n",
    "            return self.memory[opponent.name][-1][1] if self.memory[opponent.name] else \"C\"\n",
    "        elif self.strategy == \"AlwaysDefect\":\n",
    "            return \"D\"\n",
    "        elif self.strategy == \"AlwaysCooperate\":\n",
    "            return \"C\"\n",
    "        elif self.strategy == \"Grudger\":\n",
    "            return self._decide_grudger(opponent)\n",
    "        elif self.strategy == \"Pavlovian\":\n",
    "            return self._decide_pavlovian(opponent)\n",
    "        elif self.strategy == \"Appeaser\":\n",
    "            return self._decide_appeaser(opponent)\n",
    "        elif self.strategy == \"Capri\":\n",
    "            return self._decide_capri(opponent)\n",
    "        else:\n",
    "            return \"C\"  # Fallback\n",
    "\n",
    "    def _decide_grudger(self, opponent):\n",
    "        history = self.memory[opponent.name]\n",
    "        if any(opp_action == \"D\" for (_, opp_action) in history):\n",
    "            return \"D\"\n",
    "        return \"C\"\n",
    "\n",
    "    def _decide_pavlovian(self, opponent):\n",
    "        last_my_action, last_opp_action = self.memory[opponent.name][-1]\n",
    "        if last_my_action == last_opp_action:\n",
    "            return last_my_action  # Win-Stay\n",
    "        return \"D\" if last_my_action == \"C\" else \"C\"  # Lose-Shift\n",
    "\n",
    "    def _decide_appeaser(self, opponent):\n",
    "        current_action = \"C\"\n",
    "        for _, opp_action in self.memory[opponent.name]:\n",
    "            if opp_action == \"D\":\n",
    "                current_action = \"D\" if current_action == \"C\" else \"C\"\n",
    "        return current_action\n",
    "\n",
    "    def _decide_capri(self, opponent):\n",
    "        history = self.memory.get(opponent.name, [])\n",
    "        if len(history) < 3:\n",
    "            return \"C\" if random.random() < opponent.reputation else \"D\"\n",
    "\n",
    "        # Extract last 3 moves for both players\n",
    "        last3 = history[-3:]\n",
    "        last3_me = [h[0] for h in last3]  # Our last 3 actions (oldest first)\n",
    "        last3_opp = [h[1] for h in last3]  # Opponent's last 3 actions\n",
    "\n",
    "        # Rule C: Mutual cooperation\n",
    "        if last3_me == [\"C\", \"C\", \"C\"] and last3_opp == [\"C\", \"C\", \"C\"]:\n",
    "            return \"C\"\n",
    "\n",
    "        # Rule A: Accept punishment cases\n",
    "        a_cases = [\n",
    "            ([\"C\", \"C\", \"D\"], [\"C\", \"C\", \"C\"]),  # (ccd, ccc)\n",
    "            ([\"C\", \"D\", \"C\"], [\"C\", \"C\", \"D\"]),  # (cdc, ccd)\n",
    "            ([\"D\", \"C\", \"C\"], [\"C\", \"D\", \"C\"]),  # (dcc, cdc)\n",
    "            ([\"C\", \"C\", \"C\"], [\"D\", \"C\", \"C\"])   # (ccc, dcc)\n",
    "        ]\n",
    "        if (last3_me, last3_opp) in a_cases:\n",
    "            return \"C\"\n",
    "\n",
    "        # Rule P: Punish and follow-up cases\n",
    "        p_punish_case = ([\"C\", \"C\", \"C\"], [\"C\", \"C\", \"D\"])  # (ccc, ccd)\n",
    "        p_cooperate_cases = [\n",
    "            ([\"C\", \"C\", \"D\"], [\"C\", \"D\", \"C\"]),  # (ccd, cdc)\n",
    "            ([\"C\", \"D\", \"C\"], [\"D\", \"C\", \"C\"]),  # (cdc, dcc)\n",
    "            ([\"D\", \"C\", \"C\"], [\"C\", \"C\", \"C\"])   # (dcc, ccc)\n",
    "        ]\n",
    "        if (last3_me, last3_opp) == p_punish_case:\n",
    "            return \"D\"\n",
    "        elif (last3_me, last3_opp) in p_cooperate_cases:\n",
    "            return \"C\"\n",
    "\n",
    "        # Rule R: Recovery cases\n",
    "        r_cases = [\n",
    "            ([\"D\", \"D\", \"D\"], [\"D\", \"D\", \"C\"]),  # (ddd, ddc)\n",
    "            ([\"D\", \"D\", \"C\"], [\"D\", \"C\", \"C\"]),  # (ddc, dcc)\n",
    "            ([\"D\", \"C\", \"C\"], [\"C\", \"C\", \"C\"]),  # (dcc, ccc)\n",
    "            ([\"D\", \"D\", \"C\"], [\"D\", \"D\", \"D\"]),  # (ddc, ddd)\n",
    "            ([\"D\", \"C\", \"C\"], [\"D\", \"D\", \"C\"]),  # (dcc, ddc)\n",
    "            ([\"C\", \"C\", \"C\"], [\"D\", \"C\", \"C\"]),  # (ccc, dcc)\n",
    "            ([\"D\", \"D\", \"C\"], [\"D\", \"D\", \"C\"]),  # (ddc, ddc)\n",
    "            ([\"D\", \"C\", \"C\"], [\"D\", \"C\", \"C\"])   # (dcc, dcc)\n",
    "        ]\n",
    "        if (last3_me, last3_opp) in r_cases:\n",
    "            return \"C\"\n",
    "\n",
    "        # Rule I: Default to defect\n",
    "        return \"D\"\n",
    "\n",
    "\n",
    "def update_reputation(agent, action, num_friends):\n",
    "    \"\"\"\n",
    "    - If we cooperate then our reputation increases.\n",
    "    - If we deflect then our reputation decreases.\n",
    "    - It increases/decreases more for agents with less friends.\n",
    "    \"\"\"\n",
    "    scale = math.exp(-0.05 * num_friends)\n",
    "    if action == \"C\":\n",
    "        agent.reputation = min(1.0, agent.reputation + 0.1 * scale)\n",
    "    else:\n",
    "        agent.reputation = max(0.0, agent.reputation - 0.1 * scale)\n",
    "\n",
    "\n",
    "def adapt_strategy(agent, neighbors, agents, current_iteration):\n",
    "    \"\"\"\n",
    "    - We don't do strategy adoptions in first 10 rounds.\n",
    "    - After that, we adopt the strategy of neighbour with highest average payoff\n",
    "    with probability increasing with difference in our average payoffs.\n",
    "    \"\"\"\n",
    "    if current_iteration < 10:\n",
    "        return\n",
    "\n",
    "    best_neighbor = None\n",
    "    best_avg = -float('inf')\n",
    "    my_avg = agent.score / (agent.interaction_count + 1e-6)\n",
    "\n",
    "    for neighbor in neighbors:\n",
    "        neighbor_agent = agents[neighbor]\n",
    "        if neighbor_agent.interaction_count == 0:\n",
    "            continue\n",
    "        neighbor_avg = neighbor_agent.score / neighbor_agent.interaction_count\n",
    "        if neighbor_avg > best_avg and neighbor_avg > my_avg:\n",
    "            best_avg = neighbor_avg\n",
    "            best_neighbor = neighbor\n",
    "\n",
    "    if best_neighbor:\n",
    "        # Probability proportional to payoff difference\n",
    "        payoff_diff = best_avg - my_avg\n",
    "        if payoff_diff > 0:\n",
    "            prob = min(1.0, payoff_diff / (my_avg + 1e-6))\n",
    "            if random.random() < prob:\n",
    "                agent.strategy = agents[best_neighbor].strategy\n",
    "\n",
    "\n",
    "def simulate(\n",
    "    graph,\n",
    "    iterations=100,\n",
    "    interaction_csv=\"interaction.csv\",\n",
    "    strategy_csv=\"strategy_history.csv\",\n",
    "    payoff_csv=\"average_payoff.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    At each iteration, each agent plays one turn with each of its neighbours.\n",
    "    \"\"\"\n",
    "    agents = {node: Agent(node) for node in graph.nodes()}\n",
    "    # {agent: {opponent: \"CCDCD...\"}}\n",
    "    action_history = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "    for iteration in tqdm(range(iterations)):\n",
    "        # Record strategy at the **start** of the iteration\n",
    "        for agent in agents.values():\n",
    "            agent.strategy_history.append(agent.strategy)\n",
    "\n",
    "        current_edges = list(graph.edges())\n",
    "        for edge in current_edges:\n",
    "            agent1, agent2 = agents[edge[0]], agents[edge[1]]\n",
    "\n",
    "            action1 = agent1.decide(agent2)\n",
    "            action2 = agent1.decide(agent2)\n",
    "\n",
    "            # Update scores and memory\n",
    "            payoff1, payoff2 = PAYOFF_MATRIX[(action1, action2)]\n",
    "            agent1.score += payoff1\n",
    "            agent2.score += payoff2\n",
    "            agent1.interaction_count += 1\n",
    "            agent2.interaction_count += 1\n",
    "\n",
    "            agent1.memory[agent2.name].append((action1, action2))\n",
    "            agent2.memory[agent1.name].append((action2, action1))\n",
    "\n",
    "            if action1 == \"D\":\n",
    "                agent1.defection_count[agent2.name] += 1\n",
    "            if action2 == \"D\":\n",
    "                agent2.defection_count[agent1.name] += 1\n",
    "\n",
    "            # Update reputations with friend-count scaling\n",
    "            num_friends_agent1 = len(list(graph.neighbors(agent1.name)))\n",
    "            num_friends_agent2 = len(list(graph.neighbors(agent2.name)))\n",
    "            update_reputation(agent1, action1, num_friends_agent1)\n",
    "            update_reputation(agent2, action2, num_friends_agent2)\n",
    "\n",
    "            # Log actions to history\n",
    "            action_history[agent1.name][agent2.name] += action1\n",
    "            action_history[agent2.name][agent1.name] += action2\n",
    "\n",
    "        # Calculate average payoff for this iteration and append to history\n",
    "        for agent in agents.values():\n",
    "            if agent.interaction_count == 0:\n",
    "                avg = 0.0\n",
    "            else:\n",
    "                avg = agent.score / agent.interaction_count\n",
    "            agent.average_payoff_history.append(round(avg, 3))\n",
    "\n",
    "        # Update strategies (after iteration 10)\n",
    "        links_to_remove = []\n",
    "        links_to_add = []\n",
    "        for node in graph.nodes():\n",
    "            agent = agents[node]\n",
    "            neighbors = list(graph.neighbors(node))\n",
    "\n",
    "            # Possibly adapt strategy to best neighbor\n",
    "            adapt_strategy(agent, neighbors, agents, iteration)\n",
    "\n",
    "            # Break links based on defections\n",
    "            for neighbor in neighbors:\n",
    "                defections = agent.defection_count.get(neighbor, 0)\n",
    "                if random.random() < defections / 10.0:\n",
    "                    links_to_remove.append((agent.name, neighbor))\n",
    "\n",
    "            # Create links (preferential attachment)\n",
    "            current_friends = list(graph.neighbors(agent.name))\n",
    "            num_friends = len(current_friends)\n",
    "            prob_create = num_friends / (graph.number_of_nodes() + 1e-6)\n",
    "            if random.random() < prob_create:\n",
    "                non_friends = [n for n in graph.nodes(\n",
    "                ) if n != agent.name and not graph.has_edge(agent.name, n)]\n",
    "                if non_friends:\n",
    "                    new_friend = random.choice(non_friends)\n",
    "                    links_to_add.append((agent.name, new_friend))\n",
    "\n",
    "        # Apply graph changes\n",
    "        for link in links_to_remove:\n",
    "            if graph.has_edge(*link):\n",
    "                graph.remove_edge(*link)\n",
    "        for link in links_to_add:\n",
    "            if not graph.has_edge(*link):\n",
    "                graph.add_edge(*link)\n",
    "\n",
    "    print(\"Saving to csv file...\")\n",
    "    # Save interaction history\n",
    "    with open(interaction_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for agent in action_history:\n",
    "            for opponent in action_history[agent]:\n",
    "                writer.writerow(\n",
    "                    [agent, opponent, action_history[agent][opponent]])\n",
    "\n",
    "    # Save strategy history\n",
    "    with open(strategy_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"Node\"] + [str(i) for i in range(iterations)]\n",
    "        writer.writerow(header)\n",
    "        for node in agents:\n",
    "            row = [node] + agents[node].strategy_history\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Save average payoff history\n",
    "    with open(payoff_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"Player\"] + [str(i) for i in range(iterations)]\n",
    "        writer.writerow(header)\n",
    "        for node in agents:\n",
    "            row = [node] + agents[node].average_payoff_history\n",
    "            writer.writerow(row)\n",
    "\n",
    "    return agents, graph\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"reading graph..\")\n",
    "    mtx_file = \"fb_graph/matname.mtx\"\n",
    "    sparse_matrix = mmread(mtx_file)\n",
    "    print(\"finished reading graph\")\n",
    "    G = nx.Graph(sparse_matrix)\n",
    "\n",
    "    n_iter = 100\n",
    "    agents, final_graph = simulate(\n",
    "        G,\n",
    "        iterations=n_iter,\n",
    "        interaction_csv=f\"interactions_{n_iter}.csv\",\n",
    "        strategy_csv=f\"strategy_history_{n_iter}.csv\",\n",
    "        payoff_csv=f\"avg_payoff_history_{n_iter}.csv\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
